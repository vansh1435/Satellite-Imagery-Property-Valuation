{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc26386-65c2-42b9-b049-a590280e78ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# GRAD-CAM FOR SATELLITE IMAGERY (PyTorch)\n",
    "# ==========================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# DEVICE & PATHS\n",
    "# ==========================================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "IMAGE_DIR = Path(r\"C:\\Users\\vansh\\Desktop\\satellite imagery\\project_root\\images\")\n",
    "CSV_PATH = Path(r\"C:\\Users\\vansh\\Desktop\\satellite imagery\\project_root\\final_multimodal.csv\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# LOAD DATA (ONLY FOR SAMPLE SELECTION)\n",
    "# ==========================================\n",
    "fusion_df = pd.read_csv(CSV_PATH)\n",
    "fusion_df[\"id\"] = fusion_df[\"id\"].astype(int)\n",
    "\n",
    "# Keep only rows that have downloaded images\n",
    "image_ids = sorted([\n",
    "    int(float(p.stem.split(\".\")[0]))\n",
    "    for p in IMAGE_DIR.glob(\"*.png\")\n",
    "])\n",
    "\n",
    "fusion_df = (\n",
    "    fusion_df[fusion_df[\"id\"].isin(image_ids)]\n",
    "    .drop_duplicates(subset=\"id\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"Usable samples:\", fusion_df.shape)\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# SELECT LOW & HIGH PRICED SAMPLES\n",
    "# ==========================================\n",
    "cheap_samples = fusion_df.nsmallest(3, \"price\")\n",
    "expensive_samples = fusion_df.nlargest(3, \"price\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# IMAGE PREPROCESSING (SAME AS TRAINING)\n",
    "# ==========================================\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# LOAD PRETRAINED RESNET18 (FEATURE EXTRACTOR)\n",
    "# ==========================================\n",
    "model = models.resnet18(\n",
    "    weights=models.ResNet18_Weights.IMAGENET1K_V1\n",
    ")\n",
    "\n",
    "# Remove classifier (we only need features)\n",
    "model.fc = nn.Identity()\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# GRAD-CAM IMPLEMENTATION (FIXED)\n",
    "# ==========================================\n",
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.activations = None\n",
    "        self.gradients = None\n",
    "\n",
    "        # Register hooks\n",
    "        target_layer.register_forward_hook(self._forward_hook)\n",
    "        target_layer.register_full_backward_hook(self._backward_hook)\n",
    "\n",
    "    def _forward_hook(self, module, input, output):\n",
    "        self.activations = output.detach()\n",
    "\n",
    "    def _backward_hook(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0].detach()\n",
    "\n",
    "    def generate(self, input_tensor):\n",
    "        self.model.zero_grad()\n",
    "\n",
    "        output = self.model(input_tensor)\n",
    "        output.mean().backward()\n",
    "\n",
    "        # Global average pooling of gradients\n",
    "        weights = self.gradients.mean(dim=(2, 3), keepdim=True)\n",
    "        cam = (weights * self.activations).sum(dim=1)\n",
    "\n",
    "        cam = torch.relu(cam)\n",
    "        cam -= cam.min()\n",
    "        cam /= (cam.max() + 1e-8)\n",
    "\n",
    "        return cam.squeeze().cpu().numpy()\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# IMAGE LOADER\n",
    "# ==========================================\n",
    "def load_image(property_id):\n",
    "    path_1 = IMAGE_DIR / f\"{property_id}.png\"\n",
    "    path_2 = IMAGE_DIR / f\"{property_id}.0.png\"\n",
    "\n",
    "    img_path = path_1 if path_1.exists() else path_2\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "    return img, img_path\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# VISUALIZATION FUNCTION\n",
    "# ==========================================\n",
    "def show_gradcam(property_id, price, title):\n",
    "    img, img_path = load_image(property_id)\n",
    "\n",
    "    input_tensor = transform(img).unsqueeze(0).to(device)\n",
    "    input_tensor.requires_grad = True\n",
    "\n",
    "    cam = gradcam.generate(input_tensor)\n",
    "\n",
    "    # Resize CAM\n",
    "    cam = cv2.resize(cam, (224, 224))\n",
    "    heatmap = cv2.applyColorMap(\n",
    "        np.uint8(255 * cam),\n",
    "        cv2.COLORMAP_JET\n",
    "    )\n",
    "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    img_np = np.array(img.resize((224, 224)))\n",
    "    overlay = 0.6 * img_np + 0.4 * heatmap\n",
    "    overlay = overlay.astype(np.uint8)\n",
    "\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(overlay)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"{title}\\nâ‚¹{price:,}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# INITIALIZE GRAD-CAM\n",
    "# ==========================================\n",
    "gradcam = GradCAM(\n",
    "    model=model,\n",
    "    target_layer=model.layer4\n",
    ")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# VISUALIZE LOW-PRICED PROPERTIES\n",
    "# ==========================================\n",
    "for _, row in cheap_samples.iterrows():\n",
    "    show_gradcam(\n",
    "        property_id=row[\"id\"],\n",
    "        price=row[\"price\"],\n",
    "        title=\"Low-Priced Property\"\n",
    "    )\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# VISUALIZE HIGH-PRICED PROPERTIES\n",
    "# ==========================================\n",
    "for _, row in expensive_samples.iterrows():\n",
    "    show_gradcam(\n",
    "        property_id=row[\"id\"],\n",
    "        price=row[\"price\"],\n",
    "        title=\"High-Priced Property\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10c2fc2b-1ad7-4075-a55d-d93afaec2435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\vansh\\anaconda3\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in c:\\users\\vansh\\anaconda3\\lib\\site-packages (from opencv-python) (2.2.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183caa4f-2c90-4bcf-a6aa-6c976b7591f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
