<div align="center">

<!-- Animated Header -->
<img width="100%" src="https://capsule-render.vercel.app/api?type=waving&color=gradient&customColorList=12,14,18,20,24&height=180&section=header&text=SATELLITE%20PROPERTY%20VALUATION&fontSize=45&fontColor=fff&animation=fadeIn&fontAlignY=38"/>

<!-- Hero Badges -->
<p>
  <img src="https://img.shields.io/badge/Status-Active-00ff88?style=for-the-badge&labelColor=1a1a2e&logo=statuspage&logoColor=white"/>
  <img src="https://img.shields.io/badge/Python-3.8+-3776AB?style=for-the-badge&logo=python&logoColor=white&labelColor=1a1a2e"/>
  <img src="https://img.shields.io/badge/PyTorch-2.0+-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white&labelColor=1a1a2e"/>
  <img src="https://img.shields.io/badge/License-MIT-00ff88?style=for-the-badge&labelColor=1a1a2e"/>
</p>

**ğŸ›°ï¸ A multimodal machine learning project exploring how satellite imagery complements traditional housing data for property price prediction**

[Features](#-problem-overview) â€¢ [Approach](#-project-approach) â€¢ [Models](#-models-implemented) â€¢ [Setup](#-how-to-set-up-the-project) â€¢ [Findings](#-key-findings)

---

</div>

## ğŸŒŸ Overview

This project builds an end-to-end **real estate valuation pipeline** that combines:

<table>
<tr>
<td width="50%" valign="top">

### ğŸ“Š Structured Data
- Living area & lot size
- Number of bedrooms/bathrooms
- Construction quality metrics
- Geographic coordinates

</td>
<td width="50%" valign="top">

### ğŸ—ºï¸ Visual Context
- Green cover density
- Water body proximity
- Road connectivity patterns
- Urban layout features

</td>
</tr>
</table>

<div align="center">

> **Goal:** Understanding whether and how visual context adds value to property valuation

</div>

---

## ğŸ” Problem Overview

<div align="center">

```mermaid
%%{init: {'theme':'dark', 'themeVariables': {'primaryColor':'#7B2CBF', 'primaryTextColor':'#fff', 'lineColor':'#3A86FF', 'secondaryColor':'#06FFA5'}}}%%
graph LR
    A[Traditional Features] -->|Limited Context| B[Valuation Model]
    C[Satellite Imagery] -->|Neighborhood Context| B
    B --> D[Enhanced Predictions]
    
    style A fill:#3A86FF,stroke:#fff,stroke-width:2px
    style C fill:#7B2CBF,stroke:#fff,stroke-width:2px
    style D fill:#06FFA5,stroke:#fff,stroke-width:2px
    style B fill:#FF006E,stroke:#fff,stroke-width:2px
```

</div>

Traditional real estate valuation models rely heavily on structured attributes such as:

- âœ… Living area
- âœ… Number of bedrooms and bathrooms
- âœ… Construction quality
- âœ… Geographic coordinates

However, these features often fail to capture **neighborhood-level context**, such as:

- ğŸŒŠ Presence of water bodies
- ğŸŒ³ Green spaces vs concrete density
- ğŸ›£ï¸ Road connectivity and urban layout

<div align="center">

### ğŸ’¡ Research Question

> **Can satellite imagery improve property valuation when combined with tabular data?**

</div>

---

## ğŸ§  Project Approach

We follow a **multimodal regression pipeline**:

<div align="center">

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      ğŸ“ Property Location                        â”‚
â”‚                    (Latitude / Longitude)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                             â”‚
                â–¼                             â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚   ğŸ›°ï¸ Satellite API   â”‚       â”‚  ğŸ“‹ Tabular Features â”‚
     â”‚  Image Acquisition   â”‚       â”‚   â€¢ Sqft             â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚   â€¢ Beds/Baths       â”‚
                â”‚                   â”‚   â€¢ Quality          â”‚
                â–¼                   â”‚   â€¢ Year Built       â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚  ğŸ§  CNN (ResNet18)   â”‚                  â”‚
     â”‚  Image Embeddings    â”‚                  â”‚
     â”‚     (512-dim)        â”‚                  â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
                â”‚                              â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  ğŸ”— Fusion Module   â”‚
                    â”‚  Multimodal ML      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                        ğŸ’° Price Prediction
```

</div>

---

## ğŸ“‚ Repository Structure

```
satellite-property-valuation/
â”‚
â”œâ”€â”€ ğŸ“ data/
â”‚   â”œâ”€â”€ raw/                    # Original train & test datasets
â”‚   â”œâ”€â”€ processed/              # Cleaned CSVs, aligned subsets
â”‚   â””â”€â”€ images/                 # Satellite images (NOT committed)
â”‚
â”œâ”€â”€ ğŸ““ notebooks/
â”‚   â”œâ”€â”€ 01_preprocessing.ipynb        # ğŸ§¹ Data cleaning & EDA
â”‚   â”œâ”€â”€ 02_tabular_model.ipynb        # ğŸ“Š Baseline model
â”‚   â”œâ”€â”€ 03_image_model.ipynb          # ğŸ–¼ï¸ Image-only model
â”‚   â”œâ”€â”€ 04_fusion_model.ipynb         # ğŸ”— Multimodal fusion
â”‚   â”œâ”€â”€ 05_grad_cam.ipynb             # ğŸ‘ï¸ Explainability
â”‚   â””â”€â”€ 06_evaluation.ipynb           # ğŸ“ˆ Final comparison
â”‚
â”œâ”€â”€ ğŸ src/
â”‚   â””â”€â”€ data_fetcher.py         # Satellite image acquisition script
â”‚
â”œâ”€â”€ ğŸ“¤ outputs/
â”‚   â””â”€â”€ predictions.csv         # Final test predictions
â”‚
â”œâ”€â”€ ğŸ“‹ requirements.txt
â”œâ”€â”€ ğŸ“– README.md
â””â”€â”€ ğŸš« .gitignore
```

---

## ğŸ§ª Models Implemented

<div align="center">

<table>
<tr>
<td width="33%" align="center">

<img src="https://img.shields.io/badge/Model-Tabular--Only-3A86FF?style=for-the-badge&logo=databricks&logoColor=white"/>

### 1ï¸âƒ£ **Strong Baseline**

Uses structured housing features only with traditional regression models

âœ… Strong performance  
âœ… Interpretable  
âœ… Fast training  

**ğŸ¥‡ WINNER**

</td>
<td width="33%" align="center">

<img src="https://img.shields.io/badge/Model-Image--Only-7B2CBF?style=for-the-badge&logo=pytorch&logoColor=white"/>

### 2ï¸âƒ£ **Vision Model**

Satellite images â†’ ResNet18 embeddings

âš ï¸ Some signal  
âš ï¸ Noisy predictions  
âš ï¸ Needs context  

**ğŸ”´ NOISY**

</td>
<td width="33%" align="center">

<img src="https://img.shields.io/badge/Model-Multimodal-FF006E?style=for-the-badge&logo=atom&logoColor=white"/>

### 3ï¸âƒ£ **Fusion Model**

Early fusion of tabular + image embeddings

â“ Explores improvements  
â“ Critical analysis  
â“ Honest evaluation  

**ğŸŸ¡ DID NOT IMPROVE**

</td>
</tr>
</table>

</div>

---

## ğŸ“Š Key Findings

<div align="center">

| Model | RMSE | RÂ² | Performance |
|:------|:----:|:--:|:-----------:|
| **Tabular Only** | â­ Best | â­ High | ğŸ¥‡ Winner |
| **Image Only** | âš ï¸ Weak | âš ï¸ Negative | ğŸ”´ Noisy |
| **Multimodal Fusion** | â¬‡ï¸ Lower | â¬‡ï¸ Lower | ğŸŸ¡ Did not improve |

</div>

### ğŸ”‘ Key Takeaway

> **Structured tabular features provide the strongest predictive signal for property valuation.**
> 
> Satellite imagery captures meaningful neighborhood-level context (greenery, water, roads), but naÃ¯ve fusion with high-dimensional image embeddings can introduce noise and does not consistently improve predictive performance.

**This highlights the need for selective or attention-based fusion strategies in real-world multimodal systems.**

---

## ğŸ‘ï¸ Explainability with Grad-CAM

To understand *what the CNN looks at*, we apply **Grad-CAM** on satellite images.

<div align="center">

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                     ğŸ”¥ ACTIVATION PATTERNS                    â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                              â•‘
â•‘  ğŸ’ HIGH-VALUE HOMES          â”‚  ğŸšï¸ LOW-VALUE HOMES          â•‘
â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â•‘
â•‘  âœ… Water bodies              â”‚  âŒ Dense rooftops           â•‘
â•‘  âœ… Green spaces              â”‚  âŒ Concrete-heavy regions   â•‘
â•‘  âœ… Open layouts              â”‚  âŒ Industrial textures      â•‘
â•‘  âœ… Road access               â”‚  âŒ Poor connectivity        â•‘
â•‘                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

</div>

**Validation:** Satellite imagery captures **semantically meaningful spatial cues**, even when it does not directly improve regression metrics.

---

## ğŸš€ How to Set Up the Project

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/yourusername/satellite-property-valuation.git
cd satellite-property-valuation
```

### 2ï¸âƒ£ Create Virtual Environment

```bash
# Mac/Linux
python -m venv venv
source venv/bin/activate

# Windows
python -m venv venv
venv\Scripts\activate
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Set API Key (Mapbox)

Create a `.env` file in the project root:

```env
MAPBOX_TOKEN=your_mapbox_api_key_here
```

### ğŸ›°ï¸ Download Satellite Images (Optional)

Satellite images are not included due to size and API constraints. To download them:

```bash
python src/data_fetcher.py
```

This will fetch satellite images for a stratified subset of properties.

---

## â–¶ï¸ Running the Project

<div align="center">

### ğŸ“˜ Recommended Execution Order

</div>

```mermaid
%%{init: {'theme':'dark', 'themeVariables': {'primaryColor':'#7B2CBF'}}}%%
graph TD
    A[01_preprocessing.ipynb] -->|Clean Data| B[02_tabular_model.ipynb]
    B -->|Baseline| C[03_image_model.ipynb]
    C -->|Vision Model| D[04_fusion_model.ipynb]
    D -->|Multimodal| E[05_grad_cam.ipynb]
    E -->|Explainability| F[06_evaluation.ipynb]
    
    style A fill:#e3f2fd,stroke:#3A86FF,stroke-width:3px,color:#000
    style B fill:#f3e5f5,stroke:#7B2CBF,stroke-width:3px,color:#000
    style C fill:#fff3e0,stroke:#FF9800,stroke-width:3px,color:#000
    style D fill:#e8f5e9,stroke:#4CAF50,stroke-width:3px,color:#000
    style E fill:#fce4ec,stroke:#FF006E,stroke-width:3px,color:#000
    style F fill:#e0f2f1,stroke:#06FFA5,stroke-width:3px,color:#000
```

<table>
<tr>
<th>Notebook</th>
<th>Purpose</th>
<th>Output</th>
</tr>
<tr>
<td><code>01_preprocessing.ipynb</code></td>
<td>ğŸ§¹ Data cleaning & EDA</td>
<td>Cleaned datasets</td>
</tr>
<tr>
<td><code>02_tabular_model.ipynb</code></td>
<td>ğŸ“Š Baseline model</td>
<td>Performance metrics</td>
</tr>
<tr>
<td><code>03_image_model.ipynb</code></td>
<td>ğŸ–¼ï¸ Image-only model</td>
<td>CNN embeddings</td>
</tr>
<tr>
<td><code>04_fusion_model.ipynb</code></td>
<td>ğŸ”— Multimodal fusion</td>
<td>Combined predictions</td>
</tr>
<tr>
<td><code>05_grad_cam.ipynb</code></td>
<td>ğŸ‘ï¸ Explainability</td>
<td>Activation maps</td>
</tr>
<tr>
<td><code>06_evaluation.ipynb</code></td>
<td>ğŸ“ˆ Final comparison</td>
<td>Model rankings</td>
</tr>
</table>

---

## ğŸ“„ Generating Final Predictions

Final predictions on the test dataset are generated using the **best-performing tabular model**:

```
outputs/predictions.csv
```

**Format:**
```csv
id,predicted_price
1,285000
2,342000
...
```

---

## âš ï¸ Notes & Limitations

<table>
<tr>
<td width="33%" align="center">

### ğŸ¯
Satellite imagery is treated as a **complementary signal**, not a replacement

</td>
<td width="33%" align="center">

### ğŸ”¬
NaÃ¯ve fusion can degrade performance due to noisy high-dimensional features

</td>
<td width="33%" align="center">

### ğŸš€
Advanced fusion methods (attention, gating, late fusion) are proposed as future work

</td>
</tr>
</table>

---

## ğŸ”® Future Improvements

<div align="center">

| Enhancement | Impact | Status |
|:------------|:------:|:------:|
| ğŸ¯ Attention-based multimodal fusion | ğŸ”¥ High | ğŸ”µ In Progress |
| ğŸ”„ Late fusion of predictions | â­ Medium | ğŸ”µ In Progress |
| â±ï¸ Temporal satellite imagery | ğŸ”¥ High | âšª Planned |
| ğŸ“ˆ Socioeconomic context integration | â­ Medium | âšª Planned |
| ğŸ—ï¸ Architecture search (NAS) | ğŸŒŸ Low | âš« Research |
| ğŸ—ºï¸ Multi-scale spatial features | ğŸ”¥ High | âš« Research |

**Legend:** ğŸ”µ In Progress â€¢ âšª Planned â€¢ âš« Research Phase

</div>

---

## ğŸ Final Remarks

<div align="center">

**This project emphasizes engineering discipline, experimental rigor, and honest analysis over chasing marginal metric gains.**

### It demonstrates:

</div>

<table>
<tr>
<td width="25%" align="center">

### âš™ï¸
**End-to-end ML system design**

</td>
<td width="25%" align="center">

### ğŸ”—
**Multimodal data handling**

</td>
<td width="25%" align="center">

### ğŸ”
**Explainability & interpretability**

</td>
<td width="25%" align="center">

### ğŸ“Š
**Critical evaluation of results**

</td>
</tr>
</table>

---

<div align="center">

### ğŸ“« Questions or Feedback?

Open an issue or reach out!

**Made with ğŸ›°ï¸ and ğŸ§ **

<p>
  <a href="https://github.com/yourusername/satellite-property-valuation">
    <img src="https://img.shields.io/github/stars/yourusername/satellite-property-valuation?style=for-the-badge&logo=github&color=00ff88&labelColor=1a1a2e"/>
  </a>
  <a href="https://github.com/yourusername/satellite-property-valuation">
    <img src="https://img.shields.io/github/forks/yourusername/satellite-property-valuation?style=for-the-badge&logo=github&color=3A86FF&labelColor=1a1a2e"/>
  </a>
  <a href="LICENSE">
    <img src="https://img.shields.io/badge/License-MIT-FF006E?style=for-the-badge&labelColor=1a1a2e"/>
  </a>
</p>

<img width="100%" src="https://capsule-render.vercel.app/api?type=waving&color=gradient&customColorList=12,14,18,20,24&height=120&section=footer"/>

</div>
